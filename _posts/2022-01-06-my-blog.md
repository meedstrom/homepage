
# Table of Contents

1.  [Unpacking beliefs](#org85f03fe)
2.  [&ldquo;Talk to Me for an Hour&rdquo;](#org51d14d7)
3.  [A Gwern-style changelog](#orgfc8544a)
4.  [Writing advice](#org9c8033f)
5.  [Critique by others](#orgd1898ff)

Planted <span class="timestamp-wrapper"><span class="timestamp">[2022-01-06 Thu]</span></span>

-   [Publishing Org-roam notes](../2022-01-09-publishing-org-roam-notes.md)
-   [&ldquo;Blogroll&rdquo;](2022-01-17-blogroll.md)
-   [Org-roam](2022-01-04-roam.md)


<a id="org85f03fe"></a>

# Unpacking beliefs

Planted <span class="timestamp-wrapper"><span class="timestamp">[2022-01-30 Sun]</span></span>

(Note to self:  Distinguish between beliefs and forecasts.  Forecasts go on my [PredictionBook](../2022-02-14-predictionbook.md).)

Since [the purpose of my personal wiki is Cruxiness](../2022-02-14-the-purpose-of-my-personal-wiki-is-cruxiness.md), here&rsquo;s my approach.

When I write a new page summarizing my knowledge about a topic, I&rsquo;m trying to

1.  identify what I know or believe
    -   (note that in Bayesian terms, &ldquo;know&rdquo; is just a shorthand for having something like a >99.9% degree of belief, there is no &ldquo;know&rdquo;)
2.  identify where that belief comes from, or just express my [Epistemic status](../2022-01-13-epistemic-status.md) (i.e. describe my current strength of belief)
3.  if it&rsquo;s related to other pages, try to identify the mechanism by which it&rsquo;s related

For example, take a belief I previously would have verbalized as the bald statement “carbohydrates cause oxidation”.  I&rsquo;ll either expand it with a mechanism (“by way of sugar metabolism leaving behind ROS (Reactive Oxygen Species)”), or when I know no mechanism, where I got the idea from (“see correlations in study X”/”see reasoning in blog post Y”), or when I can’t be bothered, simply state my current epistemic status (“60% confident, 2022-02-14”).

A caveat is that any source I refer to should actually be where I got the idea *to start with*, not one I found later in search of confirmation.  If I don&rsquo;t remember where I got the idea, any alternative source should represent well the evidence on which I&rsquo;m actually basing my belief.  In the hypothetical case where someone debunks the source, it&rsquo;s not that I&rsquo;ll avoid moving the goalposts out of some sense of duty/fairness/principle&#x2026;  I should be *incapable* of generating the thought to move the goalposts, because that evidence was *actually* entangled with my belief, the same way a gear causes another gear to move.

In addition to increasing cruxiness, unpacking beliefs like this helps me write in an [epistemically legible](https://www.greaterwrong.com/posts/jbE85wCkRr9z7tqmD/epistemic-legibility) way; that is, make my reasoning transparent.  This maximizes readers&rsquo; ability to correct me on matters of fact and matters of bad reasoning, or at least give me a nuanced view on our exact points of disagreement.


<a id="org51d14d7"></a>

# &ldquo;Talk to Me for an Hour&rdquo;

<span class="timestamp-wrapper"><span class="timestamp">[2022-02-13 Sun]</span></span>

Elizabeth van Nostrand&rsquo;s homepage has a cool feature: [Talk to Me for an Hour](https://acesounderglass.com/2020/04/18/talk-to-me-for-an-hour-2/).

As a reader, I started to think about what I could possibly want to get her input on &#x2014; and I also realized I&rsquo;m not ready to talk to any blogger quite yet (commenting on posts is one thing, an hour&rsquo;s talk is another), but I want to.

What a way to build community. Reminds me of Sacha Chua&rsquo;s [Emacs Chats](../2022-01-23-excerpts-from-sacha-s-emacs-chats.md) series, only easier for another blogger to copy.


<a id="orgfc8544a"></a>

# A Gwern-style changelog

Jess Riedel shares the interesting links he&rsquo;s come across every month, example: <https://blog.jessriedel.com/2014/09/19/links-for-september-2014/>. The striking aspect to me is that though this is &ldquo;timeful&rdquo; content (most relevant near the point in time when it&rsquo;s posted, and ultimately has an expiration date), it&rsquo;s still neat today eight years later as listing of interesting random things.

So it&rsquo;s not *completely* pointless to have some timeful blog posts.

I could have one mega-post every month in the same style as Jess&rsquo; link collections, and additionally links to all new pages I&rsquo;ve planted in my garden, any major overhauls of existing pages, etc, like Gwern&rsquo;s changelogs. Maybe I could even scan my diary to find anything that&rsquo;s happened in my life that&rsquo;s &ldquo;bloggable&rdquo;. Fortunately with a mega-post paradigm like this, there&rsquo;s no need for me to make a whole blog post for each such event (makes me a longwinded blowhard), it&rsquo;s nice to boil them down to one paragraph.


<a id="org9c8033f"></a>

# Writing advice

> Some writings give a crystal-clear name to some idea that was complex or vague, and the idea now becomes a tool in a cognitive toolkit. These concepts are essential for thinking. You’ll think better if you have chunked vague ideas into things with names, and these names are even more essential if you want to discuss things with others, or share these vague ideas. In section 9 of his Nonfiction Writing Advice, Scott Alexander writes that some of the more important things a blog can do is to put names on such vague ideas. Scott called these “concept handles”, after previously calling them “crystallized patterns”. He says:
> 
> &ldquo;If you figure out something interesting and very briefly cram it into somebody else’s head, don’t waste that! Give it a nice concept-handle so that they’ll remember it and be able to use it to solve other problems!&rdquo;

See also Katja Grace&rsquo;s brilliant [Typology of blog posts](https://www.greaterwrong.com/posts/HjL6pkiypGwBHqrwN/typology-of-blog-posts-that-don-t-always-add-anything-clear).  She thinks a blog post does not always have to add something clear and insightful and original to the internet.  It can still be worth posting; she discusses what the blog post should achieve instead in that case.


<a id="orgd1898ff"></a>

# Critique by others

Comments can hurt, but they&rsquo;re also gold, because unlike friends who proofread you, they&rsquo;re not too worried about offending you.

> The idea of sitting down and finding the One Eternal Truth about anything is a fantasy. The universe has fractal levels of detail in every direction. There are a lot of ridiculously smart and well-informed people out there, and some of them will have deeper knowledge and insight about basically every facet of every thought you ever have. If you can motivate the collective hivemind to pay attention to something you care about, you’d be crazy not to listen.

&#x2013; <https://www.greaterwrong.com/posts/8mjoPYdeESB7ZcZvB/observations-about-writing-and-commenting-on-the-internet>

That said, you don&rsquo;t need to engage with every commenter.  Remember that while they will point out everything bad in your writing, they can still be pleasant about it.  Those who don&rsquo;t start out pleasantly are likely to never give you the closure of a resolved thread.  **The people who will pleasantly engage with you clearly signal their intention to be pleasant.**

> The tricky situation is cases where someone is mildly (or un-mildly) rude *but* also makes an intriguing point. After many failures, my policy is now to take their comments into account as much as I can and maybe reply with “thanks for your input”, but not to engage or ask follow-up questions.

Or where applicable, say &ldquo;fixed, thank you&rdquo;, or even &ldquo;sorry, I phrased it badly&rdquo;, but you don&rsquo;t need to invite further replies.

A point against epistemic legibility:

> Technically, the complaints were wrong.  How could I “fix” the problem of not citing any papers when I had already cited dozens?  That’s what I thought for months, during which people continued to read the post and have the same damned reaction.  Eventually, I had to confront that even if they were “wrong”, something about my post was *causing* them to be wrong.  Viewed that way, the problem was obvious: The idea that a humidifier could be bad for you is weird and disturbing, and weird and disturbing things are usually wrong so people are skeptical and tend to find ways to dismiss them.
> 
> *Should* they do that?
> 
> [Insert long boring polemic on Bayesian rationality]
> 
> It’s debatable—but it’s a fact that they do it.  So I rewrote the post to be “gentle”. Previously my approach was to sort of tackle the reader and scream “HUMIDIFIERS → PARTICLES!  [citation] [citation] [citation] [citation]” and “PARTICLES → DEATH! [citation] [citation] [citation]”.  I changed it to start by conceding that ultrasonic humidifiers don’t always make particles and it’s not certain those particular particles cause harm, et cetera, but PEER-REVIEWED RESEARCH PAPERS says these things are possible, so it’s worth thinking about.
> 
> After making those changes, no one had the same reaction anymore.
> 
> Part of me feels like this is wrong, that it’s disingenuous to tune writing to make people have the reaction you want them to have.  After all, I could be wrong, in which case it’s better if my wrongness is more obvious.

If you repeatedly hear the same complaint, you can presume there is a problem, though it might be very different from the problem people state.

